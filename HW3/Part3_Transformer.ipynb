{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "18sd8-wHGDR0"
   },
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "$$\n",
    "# Part 3: Transformer\n",
    "<a id=part3></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AiCHKxjfGLRu"
   },
   "source": [
    "In this part we will implement a variation of the attention mechanism named the 'sliding window attention'. Next, we will create a transformer encoder with the sliding-window attention implementation, and we will train the encoder for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:15.813911Z",
     "iopub.status.busy": "2026-01-14T03:10:15.813108Z",
     "iopub.status.idle": "2026-01-14T03:10:17.691731Z",
     "shell.execute_reply": "2026-01-14T03:10:17.690913Z"
    },
    "id": "0t2UQaeKCKxa",
    "outputId": "10e4f165-d0c0-4ac9-960a-6796ff3c1750"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import unittest\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:17.695144Z",
     "iopub.status.busy": "2026-01-14T03:10:17.694432Z",
     "iopub.status.idle": "2026-01-14T03:10:17.769101Z",
     "shell.execute_reply": "2026-01-14T03:10:17.768092Z"
    },
    "id": "35B3L7USC5PE",
    "outputId": "5e05f218-468a-4e54-c9bb-a7357f0dfe09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "test = unittest.TestCase()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2kRUk_GYNDd5"
   },
   "source": [
    "## Reminder: scaled dot product attention\n",
    "<a id=part3_1></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "30P7CuIwNKy-"
   },
   "source": [
    "In class, you saw that the scaled dot product attention is defined as:\n",
    "$$\n",
    "\\newcommand{\\mat}[1]{\\mathbf{#1}}\n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mat{B} &= \\frac{1}{\\sqrt{d}} \\mat{Q} \\mat{K}^T   \\ \\in\\set{R}^{m\\times n} \\\\\n",
    "\\mat{A} &= softmax({\\mat{B}},{\\mathrm{dim}=1}), \\in\\set{R}^{m\\times n} \\\\\n",
    "\\mat{Y} &= \\mat{A}\\mat{V} \\ \\in\\set{R}^{m\\times d_v}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where `K`,`Q` and `V` for the self attention came as projections of the same input sequnce\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\vec{q}_{i} &= \\mat{W}_{xq}\\vec{x}_{i} &\n",
    "\\vec{k}_{i} &= \\mat{W}_{xk}\\vec{x}_{i} &\n",
    "\\vec{v}_{i} &= \\mat{W}_{xv}\\vec{x}_{i} \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "If you feel the attention mechanism doesn't quite sit right, we recommend you go over lecture and tutorial notes before proceeding. \n",
    "\n",
    "We are now going to introduce a slight variation of the scaled dot product attention."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "G8CMV4VKG7YB"
   },
   "source": [
    "## Sliding window attention\n",
    "<a id=part3_2></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YphH4DuEHP1p"
   },
   "source": [
    "The scaled dot product attention computes the dot product between **every** pair of key and query vectors. Therefore, the computation complexity is $O(n^2)$ where $n$ is the sequence length.\n",
    "\n",
    "In order to obtain a computational complexity that grows linearly with the sequnce length, the authors of 'Longformer: The Long-Document Transformer https://arxiv.org/pdf/2004.05150.pdf' proposed the 'sliding window attention' which is a variation of the scaled dot product attention. \n",
    "\n",
    "In this variation, instead of computing the dot product for every pair of key and query vectors, the dot product is only computed for keys that are in a certain 'window' around the query vector. \n",
    "\n",
    "For example, if the keys and queries are embeddings of words in the sentence \"CS is more prestigious than EE\", and the window size is 2, then for the query corresponding to the word 'is' we will only compute a dot product with the keys that are at most ${window\\_size}\\over{2}$$ = $${2}\\over{2}$$=1$ to the left and to the right. Meaning the keys that correspond to the workds 'CS', 'is' and 'more'.\n",
    "\n",
    "Formally, the intermediate calculation of the normalized dot product can be written as: \n",
    "\n",
    "$$\n",
    "\\mathrm{b}(q, k, w) \n",
    "=\n",
    "\\begin{cases}\n",
    "    q⋅k^T\\over{\\sqrt{d_k}} & \\mathrm{if} \\;d(q,k) ≤ {{w}\\over{2}} \\\\\n",
    "    -\\infty & \\mathrm{otherwise}\n",
    "\\end{cases}.\n",
    "$$\n",
    "\n",
    "Where $b(\\cdot,\\cdot,\\cdot)$ is the intermediate result function (used to construct a matrix $\\mat{B}$ on which we perform the softmax), $q$ is the query vector, $k$ is the key vector, $w$ is the sliding window size, and $d(\\cdot,\\cdot)$ is the distance function between the positions of the tokens corresponding to the key and query vectors.\n",
    "\n",
    "**Note**: The distance function $d(\\cdot,\\cdot)$ is **Not** cyclical. Meaning that that in the example above when searching for the words at distance 1 from the word 'CS', we **don't** return cyclically from the right and count the word EE.\n",
    "\n",
    "The result of this operation can be visualized like this: (green corresponds to computing the scaled dot product, and white to a no-op or $-∞$).\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*0OOTgNQFQmSa3cWYj3ZbsQ.png\" width=\"700\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tZTy748cWIEC"
   },
   "source": [
    "**TODO**: Implement the sliding_window_attention function in hw3/transformer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:17.808514Z",
     "iopub.status.busy": "2026-01-14T03:10:17.808069Z",
     "iopub.status.idle": "2026-01-14T03:10:17.845271Z",
     "shell.execute_reply": "2026-01-14T03:10:17.844389Z"
    },
    "id": "CY1gz0fSebQP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1886718/1539104548.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gt_values = torch.load(os.path.join('test_tensors','values_tensor_0_heads.pt'))\n",
      "/tmp/ipykernel_1886718/1539104548.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gt_attention = torch.load(os.path.join('test_tensors','attention_tensor_0_heads.pt'))\n",
      "/tmp/ipykernel_1886718/1539104548.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gt_values = torch.load(os.path.join('test_tensors','values_tensor_3_heads.pt'))\n",
      "/tmp/ipykernel_1886718/1539104548.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gt_attention = torch.load(os.path.join('test_tensors','attention_tensor_3_heads.pt'))\n"
     ]
    }
   ],
   "source": [
    "from hw3.transformer import sliding_window_attention\n",
    "\n",
    "\n",
    "## test sliding-window attention\n",
    "num_heads = 3\n",
    "batch_size = 2\n",
    "seq_len = 5\n",
    "embed_dim = 3\n",
    "window_size = 2\n",
    "\n",
    "## test without extra dimension for heads\n",
    "x = torch.arange(seq_len*embed_dim).reshape(seq_len,embed_dim).repeat(batch_size,1).reshape(batch_size, seq_len, -1).float()\n",
    "\n",
    "values, attention = sliding_window_attention(x, x, x,window_size)\n",
    "\n",
    "gt_values = torch.load(os.path.join('test_tensors','values_tensor_0_heads.pt'))\n",
    "\n",
    "\n",
    "test.assertTrue(torch.all(values == gt_values), f'the tensors differ in dims [B,row,col]:{torch.stack(torch.where(values != gt_values),dim=0)}')\n",
    "\n",
    "gt_attention = torch.load(os.path.join('test_tensors','attention_tensor_0_heads.pt'))\n",
    "test.assertTrue(torch.all(attention == gt_attention), f'the tensors differ in dims [B,row,col]:{torch.stack(torch.where(attention != gt_attention),dim=0)}')\n",
    "\n",
    "\n",
    "## test with extra dimension for heads\n",
    "x = torch.arange(seq_len*embed_dim).reshape(seq_len,embed_dim).repeat(batch_size, num_heads, 1).reshape(batch_size, num_heads, seq_len, -1).float()\n",
    "\n",
    "values, attention = sliding_window_attention(x, x, x,window_size)\n",
    "\n",
    "gt_values = torch.load(os.path.join('test_tensors','values_tensor_3_heads.pt'))\n",
    "test.assertTrue(torch.all(values == gt_values), f'the tensors differ in dims [B,num_heads,row,col]:{torch.stack(torch.where(values != gt_values),dim=0)}')\n",
    "\n",
    "\n",
    "gt_attention = torch.load(os.path.join('test_tensors','attention_tensor_3_heads.pt'))\n",
    "test.assertTrue(torch.all(attention == gt_attention), f'the tensors differ in dims [B,num_heads,row,col]:{torch.stack(torch.where(attention != gt_attention),dim=0)}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TlHiDHhgeS1_"
   },
   "source": [
    "## Multihead Sliding window attention\n",
    "<a id=part3_2></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you've seen in class, the transformer model uses a Multi-head attention module. We will use the same implementation you've seen in the tutorial, aside from the attention mechanism itslef, which will be swapped with the sliding-window attention you implemented.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Insert the call to the sliding-window attention mechanism in the forward of MultiHeadAttention in hw3/transformer.py "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NyHo9Oy_Z7SX",
    "tags": []
   },
   "source": [
    "## Sentiment analysis\n",
    "<a id=part3_3></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6MMtJFRaZCi"
   },
   "source": [
    "We will now go on to tackling the task of sentiment analysis which is the process of analyzing text to determine if the emotional tone of the message is positive or negative (many times a neutral class is also used, but this won't be the case in the data we will be working with).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### IMBD hugging face dataset\n",
    "<a id=part3_3_1></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hugging Face is a popular open-source library and platform that provides state-of-the-art tools and resources for natural language processing (NLP) tasks. It has gained immense popularity within the NLP community due to its user-friendly interfaces, powerful pre-trained models, and a vibrant community that actively contributes to its development. \n",
    "\n",
    "Hugging Face provides a wide array of tools and utilities, which we will leverage as well. The Hugging Face Transformers library, built on top of PyTorch and TensorFlow, offers a simple yet powerful API for working with Transformer-based models (such as Distil-BERT). It enables users to easily load, fine-tune, and evaluate models, as well as generate text using these models.\n",
    "\n",
    "Furthermore, Hugging Face offers the Hugging Face Datasets library, which provides access to a vast collection of publicly available datasets for NLP. These datasets can be conveniently downloaded and used for training and evaluation purposes.\n",
    "\n",
    "You are encouraged to visit their site and see other uses: https://huggingface.co/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:17.848334Z",
     "iopub.status.busy": "2026-01-14T03:10:17.848099Z",
     "iopub.status.idle": "2026-01-14T03:10:18.758221Z",
     "shell.execute_reply": "2026-01-14T03:10:18.757210Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pathlib\n",
    "import urllib\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:18.760928Z",
     "iopub.status.busy": "2026-01-14T03:10:18.760556Z",
     "iopub.status.idle": "2026-01-14T03:10:19.380159Z",
     "shell.execute_reply": "2026-01-14T03:10:19.379215Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eran.b/miniconda3/envs/cs236781-hw/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the dataset using Hugging Face's `datasets` library.\n",
    "\n",
    "Feel free to look around at the full array of datasets that they offer.\n",
    "\n",
    "https://huggingface.co/docs/datasets/index\n",
    "\n",
    "We will load the full training and test sets in addition to a small toy subset of the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:19.383180Z",
     "iopub.status.busy": "2026-01-14T03:10:19.382632Z",
     "iopub.status.idle": "2026-01-14T03:10:26.671514Z",
     "shell.execute_reply": "2026-01-14T03:10:26.670508Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('imdb', split=['train', 'test', 'train[12480:12520]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:26.675099Z",
     "iopub.status.busy": "2026-01-14T03:10:26.674663Z",
     "iopub.status.idle": "2026-01-14T03:10:26.712811Z",
     "shell.execute_reply": "2026-01-14T03:10:26.711512Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 25000\n",
      "}), Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 25000\n",
      "}), Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 40\n",
      "})]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it returned a list of 3 labeled datasets, the first two of size 25,000, and the third of size 40.\n",
    "We will use these as `train` and `test` datasets for training the model, and the `toy` dataset for a sanity check. \n",
    "These Datasets are wrapped in a `Dataset` class.\n",
    "\n",
    "We now wrap the dataset into a `DatasetDict` class, which contains helpful methods to use for working with the data.   \n",
    "https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:26.716354Z",
     "iopub.status.busy": "2026-01-14T03:10:26.716026Z",
     "iopub.status.idle": "2026-01-14T03:10:26.750807Z",
     "shell.execute_reply": "2026-01-14T03:10:26.749869Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wrap it in a DatasetDict to enable methods such as map and format\n",
    "dataset = DatasetDict({'train': dataset[0], 'val': dataset[1], 'toy': dataset[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:26.754249Z",
     "iopub.status.busy": "2026-01-14T03:10:26.753840Z",
     "iopub.status.idle": "2026-01-14T03:10:26.794593Z",
     "shell.execute_reply": "2026-01-14T03:10:26.793594Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    toy: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 40\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access the datasets in the Dict as we would a dictionary.\n",
    "Let's print a few training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:26.798176Z",
     "iopub.status.busy": "2026-01-14T03:10:26.797845Z",
     "iopub.status.idle": "2026-01-14T03:10:26.835661Z",
     "shell.execute_reply": "2026-01-14T03:10:26.834483Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 25000\n",
      "})\n",
      "TRAINING SAMPLE 0:\n",
      "I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n",
      "Label 0: 0\n",
      "\n",
      "\n",
      "TRAINING SAMPLE 1:\n",
      "\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies.\n",
      "Label 1: 0\n",
      "\n",
      "\n",
      "TRAINING SAMPLE 2:\n",
      "If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\n",
      "Label 2: 0\n",
      "\n",
      "\n",
      "TRAINING SAMPLE 3:\n",
      "This film was probably inspired by Godard's Masculin, féminin and I urge you to see that film instead.<br /><br />The film has two strong elements and those are, (1) the realistic acting (2) the impressive, undeservedly good, photo. Apart from that, what strikes me most is the endless stream of silliness. Lena Nyman has to be most annoying actress in the world. She acts so stupid and with all the nudity in this film,...it's unattractive. Comparing to Godard's film, intellectuality has been replaced with stupidity. Without going too far on this subject, I would say that follows from the difference in ideals between the French and the Swedish society.<br /><br />A movie of its time, and place. 2/10.\n",
      "Label 3: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'])\n",
    "\n",
    "for i in range(4):\n",
    "    print(f'TRAINING SAMPLE {i}:') \n",
    "    print(dataset['train'][i]['text'])\n",
    "    label = dataset['train'][i]['label']\n",
    "    print(f'Label {i}: {label}')\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should check the label distirbution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:26.839292Z",
     "iopub.status.busy": "2026-01-14T03:10:26.838961Z",
     "iopub.status.idle": "2026-01-14T03:10:28.549440Z",
     "shell.execute_reply": "2026-01-14T03:10:28.548469Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative samples in train dataset: 12500\n",
      "positive samples in train dataset: 12500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative samples in val dataset: 12500\n",
      "positive samples in val dataset: 12500\n",
      "negative samples in toy dataset: 20\n",
      "positive samples in toy dataset: 20\n"
     ]
    }
   ],
   "source": [
    "def label_cnt(type):\n",
    "    ds = dataset[type]\n",
    "    size = len(ds)\n",
    "    cnt= 0 \n",
    "    for smp in ds:\n",
    "        cnt += smp['label']\n",
    "    print(f'negative samples in {type} dataset: {size - cnt}')\n",
    "    print(f'positive samples in {type} dataset: {cnt}')\n",
    "    \n",
    "label_cnt('train')\n",
    "label_cnt('val')\n",
    "label_cnt('toy')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __Import the tokenizer for the dataset__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s tokenize the texts into individual word tokens using the tokenizer implementation inherited from the pre-trained model class.  \n",
    "With Hugging Face you will always find a tokenizer associated with each model. If you are not doing research or experiments on tokenizers it’s always preferable to use the standard tokenizers.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:28.552453Z",
     "iopub.status.busy": "2026-01-14T03:10:28.552118Z",
     "iopub.status.idle": "2026-01-14T03:10:29.564871Z",
     "shell.execute_reply": "2026-01-14T03:10:29.563839Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer input max length: 512\n",
      "Tokenizer vocabulary size: 30522\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "print(\"Tokenizer input max length:\", tokenizer.model_max_length)\n",
    "print(\"Tokenizer vocabulary size:\", tokenizer.vocab_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create helper functions to tokenize the text. Notice the arguments sent to the tokenizer.  \n",
    "__Padding__ is a strategy for ensuring tensors are rectangular by adding a special padding token to shorter sentences.   \n",
    "On the other hand , sometimes a sequence may be too long for a model to handle. In this case, you’ll need to __truncate__ the sequence to a shorter length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:29.567872Z",
     "iopub.status.busy": "2026-01-14T03:10:29.567464Z",
     "iopub.status.idle": "2026-01-14T03:10:29.620373Z",
     "shell.execute_reply": "2026-01-14T03:10:29.619654Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_text(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    dataset_tokenized = dataset.map(tokenize_text, batched=True, batch_size =None)\n",
    "    return dataset_tokenized\n",
    "\n",
    "dataset_tokenized = tokenize_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:29.622977Z",
     "iopub.status.busy": "2026-01-14T03:10:29.622660Z",
     "iopub.status.idle": "2026-01-14T03:10:29.652039Z",
     "shell.execute_reply": "2026-01-14T03:10:29.651114Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we would like to work with pytorch so we can manually fine-tune\n",
    "dataset_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:29.654527Z",
     "iopub.status.busy": "2026-01-14T03:10:29.654230Z",
     "iopub.status.idle": "2026-01-14T03:10:29.682133Z",
     "shell.execute_reply": "2026-01-14T03:10:29.681453Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# no need to parrarelize in this assignment\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __Setting up the dataloaders and dataset__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now set up the dataloaders for efficient batching and loading of the data.  \n",
    "By now, you are familiar with the Class methods that are needed to create a working Dataloader.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:29.684816Z",
     "iopub.status.busy": "2026-01-14T03:10:29.684518Z",
     "iopub.status.idle": "2026-01-14T03:10:29.712517Z",
     "shell.execute_reply": "2026-01-14T03:10:29.711722Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:29.715025Z",
     "iopub.status.busy": "2026-01-14T03:10:29.714717Z",
     "iopub.status.idle": "2026-01-14T03:10:29.743119Z",
     "shell.execute_reply": "2026-01-14T03:10:29.742319Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.ds = dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.ds[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:29.745595Z",
     "iopub.status.busy": "2026-01-14T03:10:29.745354Z",
     "iopub.status.idle": "2026-01-14T03:10:29.773577Z",
     "shell.execute_reply": "2026-01-14T03:10:29.772763Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = IMDBDataset(dataset_tokenized['train'])\n",
    "val_dataset = IMDBDataset(dataset_tokenized['val'])\n",
    "toy_dataset = IMDBDataset(dataset_tokenized['toy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:29.776064Z",
     "iopub.status.busy": "2026-01-14T03:10:29.775826Z",
     "iopub.status.idle": "2026-01-14T03:10:29.804480Z",
     "shell.execute_reply": "2026-01-14T03:10:29.803796Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl_train,dl_val, dl_toy = [ \n",
    "    DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=12,\n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    "),\n",
    "DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=12,\n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    "),\n",
    "DataLoader(\n",
    "    dataset=toy_dataset,\n",
    "    batch_size=4,\n",
    "    num_workers=0\n",
    ")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tDSwVcumaY_E",
    "tags": []
   },
   "source": [
    "### Transformer Encoder\n",
    "<a id=part3_3_2></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qDsr_vqWa3V5"
   },
   "source": [
    "The model we will use for the task at hand, is the encoder of the transformer proposed in the seminal paper 'Attention Is All You Need'.\n",
    "\n",
    "The encoder is composed of positional encoding, and then multiple blocks which compute multi-head attention, layer normalization and a feed forward network as described in the diagram below.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"imgs/transformer_encoder.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We provided you with implemetations for the positional encoding and the position-wise feed forward MLP in hw3/transformer.py. \n",
    "\n",
    "Feel free to read through the implementations to make sure you understand what they do."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: To begin with, complete the transformer EncoderLayer in hw3/transformer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:29.807389Z",
     "iopub.status.busy": "2026-01-14T03:10:29.807150Z",
     "iopub.status.idle": "2026-01-14T03:10:29.848725Z",
     "shell.execute_reply": "2026-01-14T03:10:29.847724Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1886718/2496630226.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(os.path.join('test_tensors','encoder_layer_input.pt'))\n",
      "/tmp/ipykernel_1886718/2496630226.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y = torch.load(os.path.join('test_tensors','encoder_layer_output.pt'))\n"
     ]
    }
   ],
   "source": [
    "from hw3.transformer import EncoderLayer\n",
    "# set torch seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "layer = EncoderLayer(embed_dim=16, hidden_dim=16, num_heads=4, window_size=4, dropout=0.1)\n",
    "\n",
    "# load x and y\n",
    "x = torch.load(os.path.join('test_tensors','encoder_layer_input.pt'))\n",
    "y = torch.load(os.path.join('test_tensors','encoder_layer_output.pt'))\n",
    "padding_mask = torch.ones(2, 10)\n",
    "padding_mask[:, 5:] = 0\n",
    "\n",
    "# forward pass\n",
    "out = layer(x, padding_mask)\n",
    "test.assertTrue(torch.allclose(out, y, atol=1e-6), 'output of encoder layer is incorrect')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to classify a sentence using the encoder, we need to somehow summarize the output of the last encoder layer (which will include an output for each token in the tokenized input sentence). \n",
    "\n",
    "There are several options for doing this. We will use the output of the special token [CLS] appended to the beginning of each sentence by the bert tokenizer we are using.\n",
    "\n",
    "Let's see an example of the first tokens in a sentence after tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:29.851459Z",
     "iopub.status.busy": "2026-01-14T03:10:29.851137Z",
     "iopub.status.idle": "2026-01-14T03:10:29.885270Z",
     "shell.execute_reply": "2026-01-14T03:10:29.884418Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'i', 'rented', 'i', 'am', 'curious', '-', 'yellow', 'from', 'my']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(dataset_tokenized['train'][0]['input_ids'])[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**TODO**: Now it's time to put it all together. Complete the implementaion of 'Encoder' in hw3/transformer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:29.887866Z",
     "iopub.status.busy": "2026-01-14T03:10:29.887627Z",
     "iopub.status.idle": "2026-01-14T03:10:29.928256Z",
     "shell.execute_reply": "2026-01-14T03:10:29.927469Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1886718/537645795.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(os.path.join('test_tensors','encoder_input.pt'))\n",
      "/tmp/ipykernel_1886718/537645795.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y = torch.load(os.path.join('test_tensors','encoder_output.pt'))\n"
     ]
    }
   ],
   "source": [
    "from hw3.transformer import Encoder\n",
    "\n",
    "# set torch seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "encoder = Encoder(vocab_size=100, embed_dim=16, num_heads=4, num_layers=3, \n",
    "                  hidden_dim=16, max_seq_length=64, window_size=4, dropout=0.1)\n",
    "\n",
    "# load x and y\n",
    "x = torch.load(os.path.join('test_tensors','encoder_input.pt'))\n",
    "y = torch.load(os.path.join('test_tensors','encoder_output.pt'))\n",
    "#x = torch.randint(0, 100, (2, 64)).long()\n",
    "\n",
    "padding_mask = torch.ones(2, 64)\n",
    "padding_mask[:, 50:] = 0\n",
    "\n",
    "# forward pass\n",
    "out = encoder(x, padding_mask)\n",
    "test.assertTrue(torch.allclose(out, y, atol=1e-6), 'output of encoder layer is incorrect')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the encoder\n",
    "<a id=part3_3_3></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now proceed to train the model. \n",
    "\n",
    "**TODO**: Complete the implementation of TransformerEncoderTrainer in hw3/training.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on a toy dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we will train on a small toy dataset of 40 samples. This will serve as a sanity check to make sure nothing is buggy.\n",
    "\n",
    "**TODO**: choose the hyperparameters in hw3.answers part3_transformer_encoder_hyperparams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:29.931643Z",
     "iopub.status.busy": "2026-01-14T03:10:29.931401Z",
     "iopub.status.idle": "2026-01-14T03:10:29.961432Z",
     "shell.execute_reply": "2026-01-14T03:10:29.960651Z"
    },
    "id": "VWHBI8gm2qo-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embed_dim': 128, 'num_heads': 4, 'num_layers': 2, 'hidden_dim': 128, 'window_size': 128, 'droupout': 0.0, 'lr': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from hw3.answers import part3_transformer_encoder_hyperparams\n",
    "\n",
    "params = part3_transformer_encoder_hyperparams()\n",
    "print(params)\n",
    "embed_dim = params['embed_dim'] \n",
    "num_heads = params['num_heads']\n",
    "num_layers = params['num_layers']\n",
    "hidden_dim = params['hidden_dim']\n",
    "window_size = params['window_size']\n",
    "dropout = params['droupout']\n",
    "lr = params['lr']\n",
    "\n",
    "vocab_size = tokenizer.vocab_size\n",
    "max_seq_length = tokenizer.model_max_length\n",
    "\n",
    "max_batches_per_epoch = None\n",
    "N_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:29.963925Z",
     "iopub.status.busy": "2026-01-14T03:10:29.963688Z",
     "iopub.status.idle": "2026-01-14T03:10:31.288919Z",
     "shell.execute_reply": "2026-01-14T03:10:31.288033Z"
    }
   },
   "outputs": [],
   "source": [
    "toy_model = Encoder(vocab_size, embed_dim, num_heads, num_layers, hidden_dim, max_seq_length, window_size, dropout=dropout).to(device)\n",
    "toy_optimizer = optim.Adam(toy_model.parameters(), lr=lr)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:31.292269Z",
     "iopub.status.busy": "2026-01-14T03:10:31.291720Z",
     "iopub.status.idle": "2026-01-14T03:10:31.353529Z",
     "shell.execute_reply": "2026-01-14T03:10:31.352817Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1886718/3834131296.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  toy_saved_state = torch.load('toy_transfomer_encoder.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit your model\n",
    "import pickle\n",
    "if not os.path.exists('toy_transfomer_encoder.pt'):\n",
    "    # overfit\n",
    "    from hw3.training import TransformerEncoderTrainer\n",
    "    toy_trainer = TransformerEncoderTrainer(toy_model, criterion, toy_optimizer, device=device)\n",
    "    # set max batches per epoch\n",
    "    _ = toy_trainer.fit(dl_toy, dl_toy, N_EPOCHS, checkpoints='toy_transfomer_encoder', max_batches=max_batches_per_epoch)\n",
    "\n",
    "    \n",
    "\n",
    "toy_saved_state = torch.load('toy_transfomer_encoder.pt')\n",
    "toy_best_acc = toy_saved_state['best_acc']\n",
    "toy_model.load_state_dict(toy_saved_state['model_state']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:31.356052Z",
     "iopub.status.busy": "2026-01-14T03:10:31.355757Z",
     "iopub.status.idle": "2026-01-14T03:10:31.393836Z",
     "shell.execute_reply": "2026-01-14T03:10:31.393135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.assertTrue(toy_best_acc >= 95)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on all data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are now ready to train your sentiment analysis classifier!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:31.396514Z",
     "iopub.status.busy": "2026-01-14T03:10:31.396215Z",
     "iopub.status.idle": "2026-01-14T03:10:31.430284Z",
     "shell.execute_reply": "2026-01-14T03:10:31.429410Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_batches_per_epoch = 500\n",
    "N_EPOCHS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:31.432763Z",
     "iopub.status.busy": "2026-01-14T03:10:31.432522Z",
     "iopub.status.idle": "2026-01-14T03:10:31.511108Z",
     "shell.execute_reply": "2026-01-14T03:10:31.510214Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Encoder(vocab_size, embed_dim, num_heads, num_layers, hidden_dim, max_seq_length, window_size, dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:31.513939Z",
     "iopub.status.busy": "2026-01-14T03:10:31.513591Z",
     "iopub.status.idle": "2026-01-14T03:10:31.581318Z",
     "shell.execute_reply": "2026-01-14T03:10:31.580423Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1886718/3339141018.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_state = torch.load('trained_transfomer_encoder.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit your model\n",
    "import pickle\n",
    "if not os.path.exists('trained_transfomer_encoder.pt'):\n",
    "    from hw3.training import TransformerEncoderTrainer\n",
    "    trainer = TransformerEncoderTrainer(model, criterion, optimizer, device=device)\n",
    "    # set max batches per epoch\n",
    "    _ = trainer.fit(dl_train, dl_val, N_EPOCHS, checkpoints='trained_transfomer_encoder', max_batches=max_batches_per_epoch)\n",
    "    \n",
    "\n",
    "saved_state = torch.load('trained_transfomer_encoder.pt')\n",
    "best_acc = saved_state['best_acc']\n",
    "model.load_state_dict(saved_state['model_state']) \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:31.584599Z",
     "iopub.status.busy": "2026-01-14T03:10:31.584302Z",
     "iopub.status.idle": "2026-01-14T03:10:31.622103Z",
     "shell.execute_reply": "2026-01-14T03:10:31.621390Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.assertTrue(best_acc >= 65)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the follwing cells to see an example of the model output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:31.624664Z",
     "iopub.status.busy": "2026-01-14T03:10:31.624429Z",
     "iopub.status.idle": "2026-01-14T03:10:31.660582Z",
     "shell.execute_reply": "2026-01-14T03:10:31.659735Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19583])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_index = torch.randint(len(dataset_tokenized['val']), (1,))\n",
    "rand_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:31.663039Z",
     "iopub.status.busy": "2026-01-14T03:10:31.662790Z",
     "iopub.status.idle": "2026-01-14T03:10:31.698535Z",
     "shell.execute_reply": "2026-01-14T03:10:31.697678Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Best fan boy movie I\\'ve ever watched save \"Free Enterprise.\"<br /><br />In some ways it reminded me of an early Kevin Smith film.<br /><br />If you do any kind of role playing, this movie will likely have you laughing often at its insatiable fun. Don\\'t expect a big budget here, the acting is also questionable at times, but it really adds to the fun of the atmosphere they create. The script is truly humorous with a lot of witty moments worth experiencing.<br /><br />The bard that always gets killed had me rolling. The sexually confused player also had me smiling a bit too. But in the end... It was just a great movie showcasing some better moments in the lives of a few geeks having a great time with role playing.<br /><br />If you are bored, and ever got into role playing, this will do nicely for a distraction. A real unexpected treat.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset['val'][rand_index]\n",
    "sample['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:31.701017Z",
     "iopub.status.busy": "2026-01-14T03:10:31.700780Z",
     "iopub.status.idle": "2026-01-14T03:10:31.955022Z",
     "shell.execute_reply": "2026-01-14T03:10:31.954195Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label torch.Size([1])\n",
      "attention_mask torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: tensor([1], device='cuda:0'), prediction: tensor([1.], device='cuda:0', grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "tokenized_sample = dataset_tokenized['val'][rand_index]\n",
    "tokenized_sample\n",
    "input_ids = tokenized_sample['input_ids'].to(device)\n",
    "label = tokenized_sample['label'].to(device)\n",
    "attention_mask = tokenized_sample['attention_mask'].to(float).to(device)\n",
    "\n",
    "print('label', label.shape)\n",
    "print('attention_mask', attention_mask.shape)\n",
    "prediction = model.predict(input_ids, attention_mask).squeeze(0)\n",
    "\n",
    "print('label: {}, prediction: {}'.format(label, prediction))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part you wil see how to fine-tune a pretrained model for the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:31.957673Z",
     "iopub.status.busy": "2026-01-14T03:10:31.957376Z",
     "iopub.status.idle": "2026-01-14T03:10:31.998372Z",
     "shell.execute_reply": "2026-01-14T03:10:31.997555Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cs236781.answers import display_answer\n",
    "import hw3.answers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill your answers in hw3.answers.part3_q1 and hw3.answers.part3_q2 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain why stacking encoder layers that use the sliding-window attention results in a broader context in the final layer.\n",
    "Hint: Think what happens when stacking CNN layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:32.001160Z",
     "iopub.status.busy": "2026-01-14T03:10:32.000922Z",
     "iopub.status.idle": "2026-01-14T03:10:32.036320Z",
     "shell.execute_reply": "2026-01-14T03:10:32.035477Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Your answer:**\n",
       "\n",
       "Stacking encoder layers with sliding-window attention increases the **receptive field** of each token, similar to how stacking layers in a Convolutional Neural Network (CNN) increases the area of the input image that a deep filter can \"see.\"\n",
       "\n",
       "1. **Local View in Initial Layers:** In the first layer, each token can only attend to its immediate neighbors within the fixed window size $w$. For a query at position $i$, the context is limited to $[i - w/2, i + w/2]$.\n",
       "\n",
       "2. **Context Propagation through Depth:** In the second layer, each token's representation already contains information aggregated from its own window in the first layer. Therefore, when a query at position $i$ attends to a neighbor at position $i + w/2$, it is implicitly receiving information that the neighbor gathered from *its* neighbors further down the sequence (up to $i + w$).\n",
       "\n",
       "3. **Linear Receptive Field Growth:** With each additional layer $l$, the effective context window (receptive field) expands. For a transformer with $L$ layers and a window size $w$, the top-layer representation of a token can \"see\" a total context of approximately $L \\times w$ tokens.\n",
       "\n",
       "4. **Global Reach with Fewer Parameters:** This mechanism allows the model to build a global understanding of the text by propagating information across layers, even though each individual attention operation remains computationally efficient at $O(n \\times w)$ instead of $O(n^2)$.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_answer(hw3.answers.part3_q1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propose a variation of the attention pattern such that the computational complexity stays similar to that of the sliding-window attention O(nw), but the attention is computed on a more global context. Analyze the new time complexity, and how global information would be shared. Would it take many layers? Are there limitations to this information sharing?\n",
    "Note: There is no single correct answer to this, feel free to read the paper that proposed the sliding-window. Any solution that makes sense will be considered correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:10:32.039031Z",
     "iopub.status.busy": "2026-01-14T03:10:32.038779Z",
     "iopub.status.idle": "2026-01-14T03:10:32.073965Z",
     "shell.execute_reply": "2026-01-14T03:10:32.073109Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Your answer:**\n",
       "\n",
       "**Proposed Variation: Dilated Sliding Window Attention**\n",
       "\n",
       "Instead of attending to the $w$ immediate neighbors ($i \\pm 1, i \\pm 2, \\dots$), we attend to neighbors with a \"gap\" (dilation) of size $d$. For example, with $d=2$, a token at position $i$ attends to indices $i \\pm 2, i \\pm 4, \\dots$.\n",
       "\n",
       "1.  **Computational Complexity:**\n",
       "    The complexity remains **$O(n \\cdot w)$**.\n",
       "    Even though the attention window spans a larger distance in the text, the *number* of attention scores computed per token is still fixed at $w$. We simply skip over the tokens in the gaps.\n",
       "\n",
       "2.  **Global Information Sharing:**\n",
       "    Global information is shared much faster because the receptive field expands more rapidly.\n",
       "    * In standard sliding window, the receptive field grows linearly ($L \\times w$).\n",
       "    * In dilated attention, the receptive field is $L \\times w \\times d$.\n",
       "    If we increase the dilation rate exponentially with each layer (e.g., Layer 1 has $d=1$, Layer 2 has $d=2$, Layer 3 has $d=4$), the receptive field grows exponentially. This allows the model to \"see\" the entire sequence with very few layers (logarithmic depth).\n",
       "\n",
       "3.  **Limitations:**\n",
       "    * **The \"Gap\" Problem:** By skipping tokens, the model loses detailed local information. A token might attend to a word 10 positions away but miss the word immediately next to it.\n",
       "    * **Solution:** This is typically mitigated by using a \"Hybrid\" approach: some heads (or layers) use standard sliding window (for local details) while others use dilated window (for global context).\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_answer(hw3.answers.part3_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs236781-hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
